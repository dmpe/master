{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Design Patterns -- Source Code Examples in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developed by Dmitrij Petrov.\n",
    "\n",
    "Supress some warnings while importing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from flask.exthook import ExtDeprecationWarning\n",
    "warnings.simplefilter('ignore', ExtDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Blaze in the second pattern example requires (!) `networkx` library in version 1.11, not >= 2.x\n",
    "\n",
    "This can be installed using `sudo pip3 install networkx==1.11` from bash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #1: Notebook in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application of `Notebook` design pattern can be seen throughout this file, underpinned by the `Jupyter/IPython` package <http://jupyter.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #2: Data Frame in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 3-by-2 data frame using `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1 col2\n",
       "0     1    e\n",
       "1     2    f\n",
       "2     3    g"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # loads the package\n",
    "pd.DataFrame({'col1': [1, 2, 3], 'col2': [\"e\", \"f\", \"g\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively using `blaze` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<'list' data; _name='_1', dshape='3 * {col1: int64, col2: string}'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import blaze as bl\n",
    "bl.data([(1, \"e\"), (2, \"f\"), (3, \"g\")], fields=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #3: Tidy Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we create uing `Data Frame Design Pattern` a 3x4 table -- the same to R's example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>William</th>\n",
       "      <th>Monica</th>\n",
       "      <th>Johan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sedan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUV</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports car</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Types  William  Monica  Johan\n",
       "0       Sedan        1     0.0      0\n",
       "1         SUV        0     2.0      1\n",
       "2  Sports car        2     NaN      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_4 = pd.DataFrame.from_items([('Types', ['Sedan', 'SUV', 'Sports car']),('William', [1,0,2]),\n",
    "                                ('Monica', [0,2,None]), ('Johan', [0,1,1])])\n",
    "dp_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use previously mentioned `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>first_name</th>\n",
       "      <th>cars_owned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sedan</td>\n",
       "      <td>William</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUV</td>\n",
       "      <td>William</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports car</td>\n",
       "      <td>William</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sedan</td>\n",
       "      <td>Monica</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUV</td>\n",
       "      <td>Monica</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sports car</td>\n",
       "      <td>Monica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sedan</td>\n",
       "      <td>Johan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUV</td>\n",
       "      <td>Johan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sports car</td>\n",
       "      <td>Johan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Types first_name  cars_owned\n",
       "0       Sedan    William         1.0\n",
       "1         SUV    William         0.0\n",
       "2  Sports car    William         2.0\n",
       "3       Sedan     Monica         0.0\n",
       "4         SUV     Monica         2.0\n",
       "5  Sports car     Monica         NaN\n",
       "6       Sedan      Johan         0.0\n",
       "7         SUV      Johan         1.0\n",
       "8  Sports car      Johan         1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_tidy_df = pd.melt(dp_4, id_vars=['Types'], var_name='first_name', value_name='cars_owned')\n",
    "pandas_tidy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applies similarly to the `numpy` library - here an example with 2x3 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dp_matrix_4 = np.matrix([np.arange(3), np.arange(3,6)])\n",
    "dp_matrix_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reshape that matrix into 3 rows and 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_matrix_4.reshape((3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **next** design pattern, import `fancyimpute` package and load dataset using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "4    NaN      NaN  14.3    56      5    5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fancyimpute as fi\n",
    "airquality = pd.read_csv(\"https://gist.githubusercontent.com/dmpe/806f670cbfc4373fc4f495a828ccfbb0/raw/e8cda9fc8db497c414dc50228094adfaa6638e10/airquality.csv\", index_col = False, usecols = [1,2,3,4,5,6] )\n",
    "airquality.head().iloc[[4]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #4: Leakage in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading `fancyimpute` library as well as importing `New York's 1973 air quality` data set into Python's environment, it is inspected and observed that it contains 44 missing cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      116 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "airquality.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using `Multivariate Imputation by Chained Equations` with `Predictive Mean Matching`, missing data are imputed and a complete data frame is derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MICE] Completing matrix with shape (153, 6)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.000\n",
      "[MICE] Starting imputation round 2/110, elapsed time 0.584\n",
      "[MICE] Starting imputation round 3/110, elapsed time 0.590\n",
      "[MICE] Starting imputation round 4/110, elapsed time 0.596\n",
      "[MICE] Starting imputation round 5/110, elapsed time 0.600\n",
      "[MICE] Starting imputation round 6/110, elapsed time 0.604\n",
      "[MICE] Starting imputation round 7/110, elapsed time 0.607\n",
      "[MICE] Starting imputation round 8/110, elapsed time 0.611\n",
      "[MICE] Starting imputation round 9/110, elapsed time 0.614\n",
      "[MICE] Starting imputation round 10/110, elapsed time 0.623\n",
      "[MICE] Starting imputation round 11/110, elapsed time 0.626\n",
      "[MICE] Starting imputation round 12/110, elapsed time 0.630\n",
      "[MICE] Starting imputation round 13/110, elapsed time 0.633\n",
      "[MICE] Starting imputation round 14/110, elapsed time 0.638\n",
      "[MICE] Starting imputation round 15/110, elapsed time 0.641\n",
      "[MICE] Starting imputation round 16/110, elapsed time 0.644\n",
      "[MICE] Starting imputation round 17/110, elapsed time 0.647\n",
      "[MICE] Starting imputation round 18/110, elapsed time 0.654\n",
      "[MICE] Starting imputation round 19/110, elapsed time 0.657\n",
      "[MICE] Starting imputation round 20/110, elapsed time 0.660\n",
      "[MICE] Starting imputation round 21/110, elapsed time 0.663\n",
      "[MICE] Starting imputation round 22/110, elapsed time 0.666\n",
      "[MICE] Starting imputation round 23/110, elapsed time 0.670\n",
      "[MICE] Starting imputation round 24/110, elapsed time 0.677\n",
      "[MICE] Starting imputation round 25/110, elapsed time 0.680\n",
      "[MICE] Starting imputation round 26/110, elapsed time 0.683\n",
      "[MICE] Starting imputation round 27/110, elapsed time 0.686\n",
      "[MICE] Starting imputation round 28/110, elapsed time 0.689\n",
      "[MICE] Starting imputation round 29/110, elapsed time 0.693\n",
      "[MICE] Starting imputation round 30/110, elapsed time 0.697\n",
      "[MICE] Starting imputation round 31/110, elapsed time 0.703\n",
      "[MICE] Starting imputation round 32/110, elapsed time 0.710\n",
      "[MICE] Starting imputation round 33/110, elapsed time 0.716\n",
      "[MICE] Starting imputation round 34/110, elapsed time 0.721\n",
      "[MICE] Starting imputation round 35/110, elapsed time 0.724\n",
      "[MICE] Starting imputation round 36/110, elapsed time 0.733\n",
      "[MICE] Starting imputation round 37/110, elapsed time 0.737\n",
      "[MICE] Starting imputation round 38/110, elapsed time 0.739\n",
      "[MICE] Starting imputation round 39/110, elapsed time 0.743\n",
      "[MICE] Starting imputation round 40/110, elapsed time 0.746\n",
      "[MICE] Starting imputation round 41/110, elapsed time 0.750\n",
      "[MICE] Starting imputation round 42/110, elapsed time 0.759\n",
      "[MICE] Starting imputation round 43/110, elapsed time 0.762\n",
      "[MICE] Starting imputation round 44/110, elapsed time 0.765\n",
      "[MICE] Starting imputation round 45/110, elapsed time 0.768\n",
      "[MICE] Starting imputation round 46/110, elapsed time 0.774\n",
      "[MICE] Starting imputation round 47/110, elapsed time 0.777\n",
      "[MICE] Starting imputation round 48/110, elapsed time 0.781\n",
      "[MICE] Starting imputation round 49/110, elapsed time 0.783\n",
      "[MICE] Starting imputation round 50/110, elapsed time 0.791\n",
      "[MICE] Starting imputation round 51/110, elapsed time 0.804\n",
      "[MICE] Starting imputation round 52/110, elapsed time 0.812\n",
      "[MICE] Starting imputation round 53/110, elapsed time 0.816\n",
      "[MICE] Starting imputation round 54/110, elapsed time 0.840\n",
      "[MICE] Starting imputation round 55/110, elapsed time 0.843\n",
      "[MICE] Starting imputation round 56/110, elapsed time 0.847\n",
      "[MICE] Starting imputation round 57/110, elapsed time 0.853\n",
      "[MICE] Starting imputation round 58/110, elapsed time 0.868\n",
      "[MICE] Starting imputation round 59/110, elapsed time 0.880\n",
      "[MICE] Starting imputation round 60/110, elapsed time 0.884\n",
      "[MICE] Starting imputation round 61/110, elapsed time 0.887\n",
      "[MICE] Starting imputation round 62/110, elapsed time 0.890\n",
      "[MICE] Starting imputation round 63/110, elapsed time 0.893\n",
      "[MICE] Starting imputation round 64/110, elapsed time 0.896\n",
      "[MICE] Starting imputation round 65/110, elapsed time 0.899\n",
      "[MICE] Starting imputation round 66/110, elapsed time 0.903\n",
      "[MICE] Starting imputation round 67/110, elapsed time 0.906\n",
      "[MICE] Starting imputation round 68/110, elapsed time 0.911\n",
      "[MICE] Starting imputation round 69/110, elapsed time 0.915\n",
      "[MICE] Starting imputation round 70/110, elapsed time 0.918\n",
      "[MICE] Starting imputation round 71/110, elapsed time 0.922\n",
      "[MICE] Starting imputation round 72/110, elapsed time 0.925\n",
      "[MICE] Starting imputation round 73/110, elapsed time 0.928\n",
      "[MICE] Starting imputation round 74/110, elapsed time 0.932\n",
      "[MICE] Starting imputation round 75/110, elapsed time 0.937\n",
      "[MICE] Starting imputation round 76/110, elapsed time 0.942\n",
      "[MICE] Starting imputation round 77/110, elapsed time 0.966\n",
      "[MICE] Starting imputation round 78/110, elapsed time 0.975\n",
      "[MICE] Starting imputation round 79/110, elapsed time 0.980\n",
      "[MICE] Starting imputation round 80/110, elapsed time 0.983\n",
      "[MICE] Starting imputation round 81/110, elapsed time 0.986\n",
      "[MICE] Starting imputation round 82/110, elapsed time 0.989\n",
      "[MICE] Starting imputation round 83/110, elapsed time 0.997\n",
      "[MICE] Starting imputation round 84/110, elapsed time 1.010\n",
      "[MICE] Starting imputation round 85/110, elapsed time 1.014\n",
      "[MICE] Starting imputation round 86/110, elapsed time 1.017\n",
      "[MICE] Starting imputation round 87/110, elapsed time 1.021\n",
      "[MICE] Starting imputation round 88/110, elapsed time 1.024\n",
      "[MICE] Starting imputation round 89/110, elapsed time 1.027\n",
      "[MICE] Starting imputation round 90/110, elapsed time 1.032\n",
      "[MICE] Starting imputation round 91/110, elapsed time 1.037\n",
      "[MICE] Starting imputation round 92/110, elapsed time 1.040\n",
      "[MICE] Starting imputation round 93/110, elapsed time 1.044\n",
      "[MICE] Starting imputation round 94/110, elapsed time 1.048\n",
      "[MICE] Starting imputation round 95/110, elapsed time 1.051\n",
      "[MICE] Starting imputation round 96/110, elapsed time 1.055\n",
      "[MICE] Starting imputation round 97/110, elapsed time 1.058\n",
      "[MICE] Starting imputation round 98/110, elapsed time 1.062\n",
      "[MICE] Starting imputation round 99/110, elapsed time 1.065\n",
      "[MICE] Starting imputation round 100/110, elapsed time 1.069\n",
      "[MICE] Starting imputation round 101/110, elapsed time 1.072\n",
      "[MICE] Starting imputation round 102/110, elapsed time 1.082\n",
      "[MICE] Starting imputation round 103/110, elapsed time 1.084\n",
      "[MICE] Starting imputation round 104/110, elapsed time 1.088\n",
      "[MICE] Starting imputation round 105/110, elapsed time 1.091\n",
      "[MICE] Starting imputation round 106/110, elapsed time 1.096\n",
      "[MICE] Starting imputation round 107/110, elapsed time 1.100\n",
      "[MICE] Starting imputation round 108/110, elapsed time 1.108\n",
      "[MICE] Starting imputation round 109/110, elapsed time 1.111\n",
      "[MICE] Starting imputation round 110/110, elapsed time 1.115\n"
     ]
    }
   ],
   "source": [
    "imputedValuesArray = fi.MICE(impute_type=\"pmm\").complete(airquality.values)\n",
    "completeDF = pd.DataFrame(columns=airquality.columns, data=imputedValuesArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #5: Prototyping in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "import random\n",
    "random.seed(32018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMIndex</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  skin_thickness  insulin  BMIndex  \\\n",
       "0         6           148            72              35        0     33.6   \n",
       "1         1            85            66              29        0     26.6   \n",
       "2         8           183            64               0        0     23.3   \n",
       "3         1            89            66              23       94     28.1   \n",
       "4         0           137            40              35      168     43.1   \n",
       "\n",
       "   pedigree  age  diabetes  \n",
       "0     0.627   50         1  \n",
       "1     0.351   31         0  \n",
       "2     0.672   32         1  \n",
       "3     0.167   21         0  \n",
       "4     2.288   33         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://gist.github.com/dmpe/bfe07a29c7fc1e3a70d0522956d8e4a9\n",
    "col_names = ['num_preg', 'glucose_conc', 'diastolic_bp', 'skin_thickness', 'insulin', 'BMIndex', 'pedigree', 'age', 'diabetes']\n",
    "dt = pd.read_csv(\"https://gist.githubusercontent.com/dmpe/bfe07a29c7fc1e3a70d0522956d8e4a9/raw/7ea71f7432302bb78e58348fede926142ade6992/pima-indians-diabetes.csv\", \n",
    "                 names=col_names)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training (75%) and testing set (25%) and check for the correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = sk.model_selection.train_test_split(dt.iloc[:,0:8], dt.diabetes.values, test_size=0.25, random_state=32018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 8), (192, 8), (576,), (192,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a simple linear SVM for classification (and default hyperparameters), one can achieve very low agreement/prediction, practically slightly better than random guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sk.svm.LinearSVC(random_state = 32018)\n",
    "clf.fit(train_X, train_y)  \n",
    "predictedModel = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "ROC/AUC: 0.51\n",
      "Kappa: 0.04\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2f}\".format(accuracy_score(test_y, predictedModel)))\n",
    "print(\"ROC/AUC: {0:.2f}\".format(roc_auc_score(test_y, predictedModel)))\n",
    "print(\"Kappa: {0:.2f}\".format(cohen_kappa_score(test_y, predictedModel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.03      0.06        70\n",
      "          0       0.64      1.00      0.78       122\n",
      "\n",
      "avg / total       0.77      0.65      0.52       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predictedModel,  labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #6: Cross-validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading `scikit-learn` library, a `multinomial naive Bayes` algorithm for classification is specfied, with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha = 1.0, fit_prior = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, `5-fold cross-validation` is selected with a seed value, whereby data are not shuffled before each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle = False, random_state=32018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, diabetes values of Pima Indians are predicted using the above-mentioned classifier and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(clf, dt.iloc[:,0:8], dt.diabetes.values, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Accuracy: 0.60%\n",
      "Predicted Area Under the ROC Curve: 0.56\n",
      "Predicted Kappa: 0.13\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Accuracy: {0:0.2f}%\".format(accuracy_score(dt.diabetes.values, predicted)))\n",
    "print(\"Predicted Area Under the ROC Curve: {0:0.2f}\".format(roc_auc_score(dt.diabetes.values, predicted)))\n",
    "print(\"Predicted Kappa: {0:.2f}\".format(cohen_kappa_score(dt.diabetes.values, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #7: Grid in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training (training variables and training outcome -- class) and testing (testing variables and testing outcomes) subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = sk.model_selection.train_test_split(dt.iloc[:,0:8], dt.diabetes.values, test_size = 0.25, random_state = 32018) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the split is as we have desired it to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.00% in training set\n",
      "25.00% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(train_X)/len(dt.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(test_X)/len(dt.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define naive Bayes hyperparameters and the model itself. This model should not be compared to the R's example due to a difference in libraries & algorithms used (generally, just the family of algorithms are same - naive Bayes).\n",
    "\n",
    "Source: http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha':(1.0,0.5), 'fit_prior':[True, False]}\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grid search with 2-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridModel = GridSearchCV(mnb, parameters, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train (fit) and Test (predict) the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridModel.fit(train_X, train_y)\n",
    "y_pred = gridModel.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show best hyperparameters. Because of only having possibility of using 2 hyperparameters, the results with this dataset and trying out many other hyperparameters will not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "print(gridModel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model using accuracy and area under the curve (AUC) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "ROC/AUC: 0.53\n",
      "Predicted Kappa: 0.07\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2f}\".format(accuracy_score(test_y, y_pred)))\n",
    "print(\"ROC/AUC: {0:.2f}\".format(roc_auc_score(test_y, y_pred)))\n",
    "print(\"Predicted Kappa: {0:.2f}\".format(cohen_kappa_score(test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.39      0.40        70\n",
      "          0       0.66      0.68      0.67       122\n",
      "\n",
      "avg / total       0.57      0.57      0.57       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred,  labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model's performance is very low. Just slightly above random guessing and better than `Linear SVC`. Let's now see if ensemble models will help us here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **next** pattern, besides the library used below, one can also use `Mlxtend` of Raschka (2018; http://rasbt.github.io/mlxtend/) -- both of which work with `scikit-learn`. \n",
    "\n",
    "For this example, we have selected `ML-ENS` of Flennerhag (2018; http://ml-ensemble.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.metrics import *\n",
    "from mlens.ensemble import *\n",
    "\n",
    "# prepare these methods for our ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed similarly to R's example. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #8: Assemblage in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing `scikit-learn` and `mx-ensemble` libraries, a `stacking ensemble` is created that applies 5-fold cross-validation. It scores the models according to best accuracy, while avoiding to shuffle data before each new layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = SuperLearner(folds=5, shuffle=False, scorer=accuracy_score, \n",
    "                        random_state=32018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, `random forest` and `SVM` algorithms are added to the base level and finally, a simple meta-estimator (logit classifier) is specified for the actual step of training and testing the ensemble model.\n",
    "\n",
    "\n",
    "Only random seed is set -- all other hyperparameters take their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend=None, folds=5,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=1737, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=5, raise_on_ex...c537620>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=32018, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7f700c537620>, shuffle=False,\n",
       "       verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.add([RandomForestClassifier(random_state=32018), SVC(random_state=32018)])\n",
    "ensemble.add_meta(LogisticRegression(random_state=32018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(train_X, train_y) # train the ensemble model \n",
    "y_pred = ensemble.predict(test_X) # predict the class outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit data:\n",
      "                                   score-m  score-s  ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  randomforestclassifier       0.74     0.04  0.08  0.02  0.00  0.00\n",
      "layer-1  svc                          0.66     0.03  0.07  0.03  0.01  0.00\n",
      "\n",
      "Prediction score: 0.719\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit data:\\n%r\" % ensemble.data)\n",
    "print(\"Prediction score: %.3f\" % accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results, the prediction (accuracy) score is now much better ~ 0.72, with area under the curve of ~ 0.66.\n",
    "\n",
    "This is, when compared to the base MultinomialNB from `Grid #8`, a 15% improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "ROC/AUC: 0.66\n",
      "Predicted Kappa: 0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.44      0.53        70\n",
      "          0       0.73      0.88      0.80       122\n",
      "\n",
      "avg / total       0.71      0.72      0.70       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2f}\".format(accuracy_score(test_y, y_pred)))\n",
    "print(\"ROC/AUC: {0:.2f}\".format(roc_auc_score(test_y, y_pred)))\n",
    "print(\"Predicted Kappa: {0:.2f}\".format(cohen_kappa_score(test_y, y_pred)))\n",
    "\n",
    "print(classification_report(test_y, y_pred,  labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #9: Interactive Pattern in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seeing the `Interactive Application` using `Plot.ly Dash` framework, the reader has to navigate to the `/dp_9/python-plotly` folder and open the `app.py` file. Before that, one needs to install several packages specified in the `requirenments.txt` using `sudo pip3 install -r requirenments.txt` command.\n",
    "\n",
    "Additionally, one can see it on <http://designpattern10.herokuapp.com/> (takes some time to load)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern #10: Cloud in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `README.md` file on how to deploy interactive application to https://www.heroku.com/ in the `dp_10` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
